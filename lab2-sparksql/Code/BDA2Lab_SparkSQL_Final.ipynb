{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "sc = SparkContext(appName=\"ex2\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "temperature = spark.read.csv(\"file:///home/x_syeif/input_data/temperature-readings.csv\", header = False, sep = ';' )\n",
    "temperature = temperature.withColumnRenamed(\"_c0\", \"stationNum\")\\\n",
    "                                 .withColumnRenamed(\"_c1\", \"date\")\\\n",
    "                                 .withColumnRenamed(\"_c2\", \"time\")\\\n",
    "                                 .withColumnRenamed(\"_c3\", \"airTemp\")\\\n",
    "                                 .withColumnRenamed(\"_c4\", \"quality\")\n",
    "\n",
    "\n",
    "precipitation = spark.read.csv(\"file:///home/x_syeif/input_data/precipitation-readings.csv\", header = False, sep = ';' )\n",
    "precipitation = precipitation.withColumnRenamed(\"_c0\", \"stationNum\")\\\n",
    "                                 .withColumnRenamed(\"_c1\", \"date\")\\\n",
    "                                 .withColumnRenamed(\"_c2\", \"time\")\\\n",
    "                                 .withColumnRenamed(\"_c3\", \"precip\")\\\n",
    "                                 .withColumnRenamed(\"_c4\", \"quality\")\n",
    "\n",
    "stations = sc.textFile(\"file:///home/x_syeif/input_data/stations-Ostergotland.csv\")\\\n",
    "                            .map(lambda line: line.split(\";\"))\\\n",
    "                            .map(lambda line:line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "filtered = temperature.select(\"stationNum\", F.year(F.col('date')).alias(\"year\"),\\\n",
    "                                     F.col(\"airTemp\").cast(\"float\"))\\\n",
    "                              .filter((F.col(\"year\")>=1950) & ((F.col(\"year\")<=2014)))\n",
    "\n",
    "tempmin = filtered.groupBy(\"year\").agg(F.min('airTemp').alias('MinTemp')).orderBy(\"year\")\n",
    "\n",
    "tempmax = filtered.groupBy(\"year\").agg(F.max('airTemp').alias('MaxTemp')).orderBy(\"year\")\n",
    "            \n",
    "#out.coalesce(1).write.csv(\"file:///home/x_kesma/Lab1/input_data/results/BDA_LAB2/Q1\",sep=\",\", header=True)\n",
    "\n",
    "#print(\"----------------------------------------------------\")\n",
    "tempmin_rdd = tempmin.rdd\n",
    "tempmin_rdd.coalesce(1).saveAsTextFile(\"file:///home/x_syeif/Lab_2_Results/ex2_q1_min\")\n",
    "\n",
    "tempmax_rdd  = tempmax.rdd\n",
    "tempmax_rdd.coalesce(1).saveAsTextFile(\"file:///home/x_syeif/Lab_2_Results/ex2_q1_max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "filtered = temperature.select(\"stationNum\", F.year(F.col('date')).alias(\"year\"),\\\n",
    "                                     F.month(F.col(\"date\")).alias(\"month\"),\\\n",
    "                                     F.col(\"airTemp\").cast(\"float\"))\n",
    "\n",
    "filtered = filtered.filter(((F.col(\"year\")>=1950) & ((F.col(\"year\")<=2014))) &(F.col(\"airTemp\")>10))\n",
    "                                      \n",
    "tempcount = filtered.groupBy(\"year\", \"month\")\\\n",
    "             .agg(F.count(\"stationNum\").alias(\"res\"))\\\n",
    "             .orderBy(\"res\",ascending=False)\n",
    "\n",
    "#print(\"----------------------------------------------------\")\n",
    "tempcount_rdd = tempcount.rdd\n",
    "tempcount_rdd.coalesce(1).saveAsTextFile(\"file:///home/x_syeif/Lab_2_Results/ex2_q2_count\")\n",
    "\n",
    "\n",
    "tempdist = filtered.groupBy(\"year\", \"month\")\\\n",
    "             .agg(F.countDistinct(\"stationNum\").alias(\"res\"))\\\n",
    "             .orderBy(\"res\",ascending=False)\n",
    "\n",
    "tempdist_rdd  = tempdist.rdd\n",
    "tempdist_rdd.coalesce(1).saveAsTextFile(\"file:///home/x_syeif/Lab_2_Results/ex2_q2_dist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3\n",
    "\n",
    "filtered = temperature.select(\"stationNum\",\"date\", F.year(F.col('date')).alias(\"year\"),\\\n",
    "                                     F.month(F.col(\"date\")).alias(\"month\"),F.col(\"airTemp\").cast(\"float\"))\n",
    "                              \n",
    "filtered = filtered.filter((F.col(\"year\")>=1960) & ((F.col(\"year\")<=2014)))\n",
    "\n",
    "## Fix: Calculating daily avg of min and Max Temperatute and then caluclating overall avg \n",
    "filtered = filtered.groupBy('date', 'stationNum').agg(F.min('airTemp').alias('minTemp'),\\\n",
    "                                                     F.max('airTemp').alias('maxTemp'))\n",
    "\n",
    "tempavg = filtered.select('date','stationNum',((F.col('minTemp')+F.col('maxTemp'))/2.0).alias('dailyAvg'))\\\n",
    "                    .groupBy(F.year(F.col('date')),F.month(F.col('date')),'stationNum')\\\n",
    "                    .agg(F.avg('dailyAvg').alias('avgMonthlyTemperature'))\\\n",
    "            .orderBy('avgMonthlyTemperature',ascending=False)\n",
    "\n",
    "#print(\"----------------------------------------------------\")\n",
    "tempavg_rdd = tempavg.rdd\n",
    "tempavg_rdd.coalesce(1).saveAsTextFile(\"file:///home/x_syeif/Lab_2_Results/ex2_q3_avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4\n",
    "\n",
    "# MAP\n",
    "temperature1 = sc.textFile(\"file:///home/x_syeif/input_data/temperature-readings.csv\")\n",
    "lines = temperature1.map(lambda x: x.split(\";\"))\n",
    "\n",
    "#converting lines to rows for temperature\n",
    "convertedrows = lines.map(lambda x: Row(station=x[0], year=x[1].split(\"-\")[0],\n",
    "month=x[1].split(\"-\")[1],day=x[1].split(\"-\")[2], time=x[2], temperature=float(x[3]), quality=x[4] ))\n",
    "\n",
    "TempReadings = sqlContext.createDataFrame(convertedrows)\n",
    "TempReadings.registerTempTable(\"convertedrows_sql\")\n",
    "\n",
    "#spark.sql(\"select max(temperature) as maxTemp from convertedrows_sql\")\n",
    "\n",
    "tempmax = schemaTempReadings.groupBy('station').agg(F.max('temperature').alias('maxTemperature'))\\\n",
    ".orderBy(['maxTemperature'],ascending=False)\n",
    "\n",
    "filtertemperature = tempmax.filter((F.col(\"maxTemperature\") > 25)  & ( F.col(\"maxTemperature\") < 30))\n",
    "\n",
    "\n",
    "precipitation = sc.textFile(\"file:///home/x_syeif/input_data/precipitation-readings.csv\")\n",
    "lines = precipitation.map(lambda x: x.split(\";\"))\n",
    "\n",
    "#converting lines to rows for precipitation\n",
    "convertedrows1 = lines.map(lambda x: Row(station=x[0], year=x[1].split(\"-\")[0],\n",
    "month=x[1].split(\"-\")[1],day=x[1].split(\"-\")[2], time=x[2], precipitation=float(x[3]), quality=x[4] ))\n",
    "\n",
    "PrecipReadings = sqlContext.createDataFrame(convertedrows1)\n",
    "PrecipReadings.registerTempTable(\"convertedrows1\")\n",
    "\n",
    "## Fix: Added Summation of precipitation per station before taking max\n",
    "prepsum = PrecipReadings.groupBy('station').agg(F.sum('precipitation').alias('precipitation'))\n",
    "\n",
    "precpmax = prepsum.groupBy('station').agg(F.max('precipitation').alias('maxPrec')).orderBy(['maxPrec'],ascending=False)\n",
    "\n",
    "filterprec = precpmax.filter((F.col(\"maxPrec\") > 100 ) & (F.col(\"maxPrec\") < 200))\n",
    "\n",
    "jointempprec = filtertemperature.join(filterprec, on=\"station\",how=\"inner\").select(\"station\", \"maxTemperature\", \"maxPrec\").orderBy([\"station\"], ascending=False)\n",
    "\n",
    "\n",
    "#print(\"----------------------------------------------------\")\n",
    "finaltempprec_rdd = jointempprec.rdd\n",
    "finaltempprec_rdd.coalesce(1).saveAsTextFile(\"file:///home/x_syeif/Lab_2_Results/ex2_q4_filteredtempprec\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-7a427d53f8f3>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-7a427d53f8f3>\"\u001b[1;36m, line \u001b[1;32m16\u001b[0m\n\u001b[1;33m    precpsum = filterprec.groupBy('station', 'year', 'month').agg(F.sum('precipitation').alias('sumprec')).orderBy(['year', 'month'],ascending=False)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Q5 \n",
    "\n",
    "precipitation = sc.textFile(\"file:///home/x_syeif/input_data/precipitation-readings.csv\")\n",
    "lines = precipitation.map(lambda x: x.split(\";\"))\n",
    "\n",
    "#converting lines to rows for precipitation\n",
    "convertedrows1 = lines.map(lambda x: Row(station=x[0], year=x[1].split(\"-\")[0],\n",
    "month=x[1].split(\"-\")[1],day=x[1].split(\"-\")[2], time=x[2], precipitation=float(x[3]), quality=x[4] ))\n",
    "\n",
    "PrecipReadings = sqlContext.createDataFrame(convertedrows1)\n",
    "PrecipReadings.registerTempTable(\"convertedrows1\")\n",
    "\n",
    "\n",
    "filterprec = PrecipReadings.filter(PrecipReadings[\"year\"].between(\"1993\", \"2016\"))\n",
    "\n",
    "\n",
    "precpsum = filterprec.groupBy('station', 'year', 'month').agg(F.sum('precipitation').alias('sumprec')).orderBy(['year', 'month'],ascending=[0,0])\n",
    "\n",
    "Osterstation = sc.textFile(\"file:///home/x_syeif/input_data/stations-Ostergotland.csv\")\n",
    "lines = Osterstation.map(lambda x: x.split(\";\"))\n",
    "\n",
    "#converting lines to rows for stations\n",
    "convertedrowstation = lines.map(lambda x: Row(stnumber=x[0], stname=x[1], stheight=float(x[2]), stlatitude=float(x[3]), stlongitude=float(x[4])))\n",
    "\n",
    "                                   \n",
    "OsterReadings = sqlContext.createDataFrame(convertedrowstation)\n",
    "OsterReadings.registerTempTable(\"convertedrowstation\")\n",
    "                                   \n",
    "                                   \n",
    "#Join \n",
    "joinprecstation = precpsum.join(OsterReadings, precpsum[\"station\"] ==OsterReadings[\"stnumber\"], how=\"inner\").groupBy(\"year\", \"month\").agg(F.mean(\"sumprec\").alias(\"precavg\")).orderBy([\"year\",\"month\"], ascending=False).select(\"year\", \"month\", \"precavg\")\n",
    "\n",
    "\n",
    "#print(\"----------------------------------------------------\")\n",
    "joinprecstation_rdd = joinprecstation.rdd\n",
    "joinprecstation_rdd.coalesce(1).saveAsTextFile(\"file:///home/x_syeif/Lab_2_Results/ex2_q5_avg\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
